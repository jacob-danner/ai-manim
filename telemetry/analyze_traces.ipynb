{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telemetry Trace Analysis\n",
    "\n",
    "Minimal notebook to connect to trace files and query with DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded traces from test_traces.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Connect to DuckDB\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Load trace data (adjust path as needed)\n",
    "# trace_file = \"traces.jsonl\"  # Main telemetry file\n",
    "trace_file = \"test_traces.jsonl\"  # Test file\n",
    "\n",
    "if Path(trace_file).exists():\n",
    "    conn.execute(f\"\"\"\n",
    "        CREATE TABLE traces AS \n",
    "        SELECT * FROM read_json_auto('{trace_file}')\n",
    "    \"\"\")\n",
    "    print(f\"✅ Loaded traces from {trace_file}\")\n",
    "else:\n",
    "    print(f\"❌ Trace file not found: {trace_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────────────────┬──────────────────┬──────────────────┬──────────────────────────────────┬─────────────────────┬─────────────────────┬─────────────┬─────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│             trace_id             │     span_id      │  parent_span_id  │               name               │     start_time      │      end_time       │ duration_ns │ status_code │                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  attributes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  │ events │                                                                          resource_attributes                                                                          │\n",
       "│             varchar              │     varchar      │     varchar      │             varchar              │        int64        │        int64        │    int64    │   varchar   │                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       struct(\"input.mime_type\" varchar, \"input.value\" varchar, \"llm.model_name\" varchar, \"llm.provider\" varchar, \"llm.invocation_parameters\" varchar, \"llm.input_messages.0.message.role\" varchar, \"llm.input_messages.0.message.content\" varchar, \"llm.input_messages.1.message.role\" varchar, \"llm.input_messages.1.message.content\" varchar, \"output.value\" varchar, \"output.mime_type\" varchar, \"llm.output_messages.0.message.role\" varchar, \"llm.output_messages.0.message.content\" varchar, \"openinference.span.kind\" varchar)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        │ json[] │      struct(\"telemetry.sdk.language\" varchar, \"telemetry.sdk.name\" varchar, \"telemetry.sdk.version\" varchar, \"service.name\" varchar, \"service.version\" varchar)       │\n",
       "├──────────────────────────────────┼──────────────────┼──────────────────┼──────────────────────────────────┼─────────────────────┼─────────────────────┼─────────────┼─────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ b0ae951d37ec9912619e9790fb44d4ec │ a61bda22b7d4878b │ 34509f5ba1cd354d │ LM.__call__                      │ 1754010606582776000 │ 1754010607442638000 │   859862000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"prompt\": null, \"messages\": [{\"role\": \"system\", \"content\": \"Your input fields are:\\\\n1. `input_text` (str): Test input\\\\nYour output fields are:\\\\n1. `reasoning` (str): \\\\n2. `output_text` (str): Test output\\\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\\\n\\\\n[[ ## input_text ## ]]\\\\n{input_text}\\\\n\\\\n[[ ## reasoning ## ]]\\\\n{reasoning}\\\\n\\\\n[[ ## output_text ## ]]\\\\n{output_text}\\\\n\\\\n[[ ## completed ## ]]\\\\nIn adhering to this structure, your objective is: \\\\n        Test signature for telemetry\"}, {\"role\": \"user\", \"content\": \"[[ ## input_text ## ]]\\\\nHello, world!\\\\n\\\\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## output_text ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\"}], \"kwargs\": {}}', 'llm.model_name': google/gemini-2.5-flash, 'llm.provider': openrouter, 'llm.invocation_parameters': '{\"temperature\": 0.0, \"max_tokens\": 100}', 'llm.input_messages.0.message.role': system, 'llm.input_messages.0.message.content': 'Your input fields are:\\n1. `input_text` (str): Test input\\nYour output fields are:\\n1. `reasoning` (str): \\n2. `output_text` (str): Test output\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## input_text ## ]]\\n{input_text}\\n\\n[[ ## reasoning ## ]]\\n{reasoning}\\n\\n[[ ## output_text ## ]]\\n{output_text}\\n\\n[[ ## completed ## ]]\\nIn adhering to this structure, your objective is: \\n        Test signature for telemetry', 'llm.input_messages.1.message.role': user, 'llm.input_messages.1.message.content': '[[ ## input_text ## ]]\\nHello, world!\\n\\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## output_text ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.', 'output.value': '[\"[[ ## reasoning ## ]]\\\\nThe user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\\\\n[[ ## output_text ## ]]\\\\nTest output for \\\\\"Hello, world!\\\\\"\\\\n[[ ## completed ## ]]\"]', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': assistant, 'llm.output_messages.0.message.content': '[[ ## reasoning ## ]]\\nThe user provided \"Hello, world!\" as input. I need to provide a test output.\\n[[ ## output_text ## ]]\\nTest output for \"Hello, world!\"\\n[[ ## completed ## ]]', 'openinference.span.kind': LLM} │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ b0ae951d37ec9912619e9790fb44d4ec │ 34509f5ba1cd354d │ 4256019b6f7323c6 │ ChatAdapter.__call__             │ 1754010606582474000 │ 1754010607443211000 │   860737000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"lm\": \"<dspy.clients.lm.LM object at 0x16abc4140>\", \"lm_kwargs\": {}, \"signature\": \"StringSignature(input_text -> reasoning, output_text\\\\n    instructions=\\'Test signature for telemetry\\'\\\\n    input_text = Field(annotation=str required=True json_schema_extra={\\'desc\\': \\'Test input\\', \\'__dspy_field_type\\': \\'input\\', \\'prefix\\': \\'Input Text:\\'})\\\\n    reasoning = Field(annotation=str required=True json_schema_extra={\\'prefix\\': \\\\\"Reasoning: Let\\'s think step by step in order to\\\\\", \\'desc\\': \\'${reasoning}\\', \\'__dspy_field_type\\': \\'output\\'})\\\\n    output_text = Field(annotation=str required=True json_schema_extra={\\'desc\\': \\'Test output\\', \\'__dspy_field_type\\': \\'output\\', \\'prefix\\': \\'Output Text:\\'})\\\\n)\", \"demos\": [], \"inputs\": {\"input_text\": \"Hello, world!\"}}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '[{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}]', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ b0ae951d37ec9912619e9790fb44d4ec │ 4256019b6f7323c6 │ d7200b3a387a48a0 │ Predict(StringSignature).forward │ 1754010606582378000 │ 1754010607443493000 │   861115000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"input_text\": \"Hello, world!\"}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ b0ae951d37ec9912619e9790fb44d4ec │ d7200b3a387a48a0 │ b19cf00382c13498 │ Predict.forward                  │ 1754010606582327000 │ 1754010607443637000 │   861310000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"input_text\": \"Hello, world!\"}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ b0ae951d37ec9912619e9790fb44d4ec │ b19cf00382c13498 │ e074bc6dc3b1e146 │ ChainOfThought.forward           │ 1754010606582270000 │ 1754010607443775000 │   861505000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"input_text\": \"Hello, world!\"}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ b0ae951d37ec9912619e9790fb44d4ec │ e074bc6dc3b1e146 │ NULL             │ TestModule.forward               │ 1754010606582194000 │ 1754010607443903000 │   861709000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"input_text\": \"Hello, world!\"}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ ecd228ad0c739496b267edbfa564b0b4 │ ee94f52f4bf29340 │ 278de0b96108012b │ LM.__call__                      │ 1754011141797650000 │ 1754011141797940000 │      290000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"prompt\": null, \"messages\": [{\"role\": \"system\", \"content\": \"Your input fields are:\\\\n1. `input_text` (str): Test input\\\\nYour output fields are:\\\\n1. `reasoning` (str): \\\\n2. `output_text` (str): Test output\\\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\\\n\\\\n[[ ## input_text ## ]]\\\\n{input_text}\\\\n\\\\n[[ ## reasoning ## ]]\\\\n{reasoning}\\\\n\\\\n[[ ## output_text ## ]]\\\\n{output_text}\\\\n\\\\n[[ ## completed ## ]]\\\\nIn adhering to this structure, your objective is: \\\\n        Test signature for telemetry\"}, {\"role\": \"user\", \"content\": \"[[ ## input_text ## ]]\\\\nHello, world!\\\\n\\\\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## output_text ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\"}], \"kwargs\": {}}', 'llm.model_name': google/gemini-2.5-flash, 'llm.provider': openrouter, 'llm.invocation_parameters': '{\"temperature\": 0.0, \"max_tokens\": 100}', 'llm.input_messages.0.message.role': system, 'llm.input_messages.0.message.content': 'Your input fields are:\\n1. `input_text` (str): Test input\\nYour output fields are:\\n1. `reasoning` (str): \\n2. `output_text` (str): Test output\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## input_text ## ]]\\n{input_text}\\n\\n[[ ## reasoning ## ]]\\n{reasoning}\\n\\n[[ ## output_text ## ]]\\n{output_text}\\n\\n[[ ## completed ## ]]\\nIn adhering to this structure, your objective is: \\n        Test signature for telemetry', 'llm.input_messages.1.message.role': user, 'llm.input_messages.1.message.content': '[[ ## input_text ## ]]\\nHello, world!\\n\\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## output_text ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.', 'output.value': '[\"[[ ## reasoning ## ]]\\\\nThe user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\\\\n[[ ## output_text ## ]]\\\\nTest output for \\\\\"Hello, world!\\\\\"\\\\n[[ ## completed ## ]]\"]', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': assistant, 'llm.output_messages.0.message.content': '[[ ## reasoning ## ]]\\nThe user provided \"Hello, world!\" as input. I need to provide a test output.\\n[[ ## output_text ## ]]\\nTest output for \"Hello, world!\"\\n[[ ## completed ## ]]', 'openinference.span.kind': LLM} │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ ecd228ad0c739496b267edbfa564b0b4 │ 278de0b96108012b │ 4e2959b28b290823 │ ChatAdapter.__call__             │ 1754011141797358000 │ 1754011141798150000 │      792000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"lm\": \"<dspy.clients.lm.LM object at 0x13c734230>\", \"lm_kwargs\": {}, \"signature\": \"StringSignature(input_text -> reasoning, output_text\\\\n    instructions=\\'Test signature for telemetry\\'\\\\n    input_text = Field(annotation=str required=True json_schema_extra={\\'desc\\': \\'Test input\\', \\'__dspy_field_type\\': \\'input\\', \\'prefix\\': \\'Input Text:\\'})\\\\n    reasoning = Field(annotation=str required=True json_schema_extra={\\'prefix\\': \\\\\"Reasoning: Let\\'s think step by step in order to\\\\\", \\'desc\\': \\'${reasoning}\\', \\'__dspy_field_type\\': \\'output\\'})\\\\n    output_text = Field(annotation=str required=True json_schema_extra={\\'desc\\': \\'Test output\\', \\'__dspy_field_type\\': \\'output\\', \\'prefix\\': \\'Output Text:\\'})\\\\n)\", \"demos\": [], \"inputs\": {\"input_text\": \"Hello, world!\"}}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '[{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}]', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ ecd228ad0c739496b267edbfa564b0b4 │ 4e2959b28b290823 │ 05d17a342d2cd214 │ Predict(StringSignature).forward │ 1754011141797271000 │ 1754011141798431000 │     1160000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"input_text\": \"Hello, world!\"}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ ecd228ad0c739496b267edbfa564b0b4 │ 05d17a342d2cd214 │ 7506776ea9e00758 │ Predict.forward                  │ 1754011141797220000 │ 1754011141798506000 │     1286000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"input_text\": \"Hello, world!\"}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ ecd228ad0c739496b267edbfa564b0b4 │ 7506776ea9e00758 │ f41cd7f1366b384b │ ChainOfThought.forward           │ 1754011141797165000 │ 1754011141798569000 │     1404000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"input_text\": \"Hello, world!\"}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "│ ecd228ad0c739496b267edbfa564b0b4 │ f41cd7f1366b384b │ NULL             │ TestModule.forward               │ 1754011141797092000 │ 1754011141798628000 │     1536000 │ OK          │ {'input.mime_type': application/json, 'input.value': '{\"input_text\": \"Hello, world!\"}', 'llm.model_name': NULL, 'llm.provider': NULL, 'llm.invocation_parameters': NULL, 'llm.input_messages.0.message.role': NULL, 'llm.input_messages.0.message.content': NULL, 'llm.input_messages.1.message.role': NULL, 'llm.input_messages.1.message.content': NULL, 'output.value': '{\"reasoning\": \"The user provided \\\\\"Hello, world!\\\\\" as input. I need to provide a test output.\", \"output_text\": \"Test output for \\\\\"Hello, world!\\\\\"\"}', 'output.mime_type': application/json, 'llm.output_messages.0.message.role': NULL, 'llm.output_messages.0.message.content': NULL, 'openinference.span.kind': CHAIN}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │ []     │ {'telemetry.sdk.language': python, 'telemetry.sdk.name': opentelemetry, 'telemetry.sdk.version': 1.36.0, 'service.name': ai-manim-pipeline, 'service.version': 0.1.0} │\n",
       "├──────────────────────────────────┴──────────────────┴──────────────────┴──────────────────────────────────┴─────────────────────┴─────────────────────┴─────────────┴─────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ 12 rows                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                11 columns │\n",
       "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic query - see all traces\n",
    "conn.sql(\"SELECT * FROM traces\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-visualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
